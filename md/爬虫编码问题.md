**爬虫中的编码问题**

1. 请求头中有个字段，Accept-Encoding 告诉server可以接收的文件格式。如果server以gzip返回数据，则脚本就不能正确解析。需要[zlib库](https://cnodejs.org/topic/532269f4d7ede09c72000a88)。或者干脆不定义这个字段，让server不压缩返回数据。
或者options中加入字段gzip=true
    关于gzip [==========资料===============](https://www.douban.com/note/270480725/)
2. 拿到的网页meta标签规定的字符集charset=GBk或gb2312。如理方法是request模块的options的encoding字段设置为null。意思就是拿到buffer数据后先不转换成字符串。（request模块默认会使用utf-8字符集转换字符串，即对返回结果自动调用toString()方法，并且参数选择默认的utf-8）。nodejs的Buffer对象不支持使用GBK转换字符串，需要引入一个外部库iconv-lite。这是一个javascript实现的库。可以把buffer使用GBK编码转换成字符串。


**爬虫队列**

比如小说有1000+张，怎么控制并发数，怎么设置队列？开源框架crawler的使用。爬取js渲染页面的话，使用phantomjs

[nodejs爬虫-cnode社区-i5ting](https://cnodejs.org/topic/57c529cf9b447b634391c814)

[http头信息referer作用](http://www.zhaoyoucai.com/33.html)
[http协议字段文档](https://tools.ietf.org/html/rfc7231)